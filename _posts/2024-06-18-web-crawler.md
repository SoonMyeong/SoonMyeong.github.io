---
layout: post
title: 대규모시스템설계기초- 9장 웹크롤러 설계
subtitle: 웹크롤러 설계
categories: book
tags: [crawler, web]
---

# 웹 크롤러의 목적

- 웹에 새로 올라오거나 갱신된 콘텐츠를 찾아 내는 것

## 크롤러의 종류

- 검색 엔진 인덱싱
  - 가장 보편적인 용례
  - ex) 구글 검색 엔진이 사용하는 웹 크롤러 = 구글봇
- 웹 아카이빙
  - 나중에 사용할 목적으로 장기보관을 위해 웹에서 정보를 모으는 절차
- 웹 마이닝
  - 인터넷에서 유용한 지식을 도출해 낼 수 있는 것
  - ex) 주주총회 자료나 연차 보고서 같은걸 다운 받아 기업의 핵심 사업방향 캐치
- 웹 모니터링
  - 인터넷에서 저작권이나 상표권이 침해되는 사례 모니터링

# 1단계. 문제 이해 및 설계 범위 확정

웹 크롤러의  기본 알고리즘

1. URL 집합이 입력으로 주어지면, 해당 URL 들이 가리키는 모든 웹페이지 다운로드
2. 다운받은 웹페이지에서 URL들을 추출
3. 추출된 URL 들을 다운로드할 URL 목록에 추가하고 위 과정을 처음부터 반복

이번에 설계할 크롤러는 검색 엔진 인덱싱에 쓰일 크롤러

### 좋은 웹 크롤러가 만족시켜야 할 속성

- 규모 확장성
  - 웹은 거대하기 때문에 병행성을 활용 시 보다 효과적
- 안정성
  - 비정상적 입력이나 환경에 잘 대응해야 함
- 예절
  - 짧은 시간에 너무 많은 요청은… X
- 확장성
  - 새로운 형태의 콘텐츠를 지원하기 쉬워야 한다

# 2단계. 개략적 설계안 제시 및 동의 구하기

![1](https://github.com/SoonMyeong/SoonMyeong.github.io/assets/31875043/00eaab6e-15a5-4832-a335-55d16da4b707)

그림1. 설계안

- 이 구조는 http://infolab.stanford.edu/~olston/publications/crawling_survey.pdf 를 참고함

### 시작 URL 집합

- 웹 크롤러가 크롤링을 시작하는 출발점
- 전체 웹을 크롤링 할 경우 일반적으로 전체 URL 공간을 작은 부분집합으로 나누는 전략을 쓴다.

### 미수집 URL 저장소

- 다운로드할 URL을 저장 관리하는 큐라고 생각하면 됨

### 도메인 이름 변환기

- URL 을 IP 주소로 변환하는 절차

### 콘텐츠 파서

- 웹페이지 다운 후 파싱과 검증 절차를 담당
  - 이상한 웹 페이지를 걸러내기 위해

### 중복 컨텐츠?

- 웹 페이지의 해시 값을 비교 해 중복을 줄여 데이터 처리 소요 시간을 줄이는 목적

### 컨텐츠 처장소

- HTML 문서 저장소
- 인기 있는 컨텐츠는 메모리에 두어 접근 지연시간을 줄일 것

### URL 추출기

- HTML 페이지 파싱 하여 링크 골라내는 역할
- 상대 경로는 전부 절대경로로 변환

### URL 필터

- 크롤링 대상에서 배제하는 역할

### 이미 방문한 URL?

- 이미 방문한적 있는 URL 인지 체크하는 역할
- 블룸필터나 해시테이블이 널리 쓰임

### URL 저장소

- 이미 방문한 URL을 보관하는 저장소

## 웹 크롤러 작업 흐름

![3](https://github.com/SoonMyeong/SoonMyeong.github.io/assets/31875043/3d6eb3b1-f156-4089-8de1-5e808771c879)

6.저장소에 없는 컨텐츠면 저장소에 저장한 뒤 URL 추출기로 전달 \
7.추출기에서 링크를 골라냄\
11.저장소에 없는 URL은 URL 저장소에 저장할 뿐만아니라 미수집 URL 저장소에도 전달한다.
- 해당 URL 은 추출만 했고 컨텐츠를 안뽑아먹었으니까

# 3단계. 상세 설계

### DFS vs BFS

- DFS 로 구성 시 깊이가 어느정도 깊게 가게될지 가늠하기 어려움
- 그래서 보통 BFS 를 사용함
- 보통 큐의 한쪽에는 탐색할 URL을 집어넣고, 다른 한쪽은 꺼내기만 하는데..
  - 한 페이지에서 나오는 링크의 상당수는 같은 서버로 되돌아간다.
  - 병렬로 처리 시 예의 없는 크롤러로 간주된다.
- 표준 BFS 알고리즘은 URL 간 우선순위를 두지 않음.
  - 페이지 순위, 트래픽양, 업데이트 빈도 등 여러 가지 척도에 비춰 처리 우선순위를 구별하는 것이 온당하다.

### 미수집 URL 저장소

- 미수집 URL 저장소로 위 문제를 쉽게 해결 할 수 있다.
  - URL 사이의 우선순위와 신선도를 구별하는 크롤러를 구현할 수 있어서
- 예의
  - 예의바른 크롤러로 만드는 데 있어 지켜야 할 한가지 원칙
    - 동일 웹 사이트에 대해 한 번에 한 페이지만 요청한다.
    - 같은 웹 사이트의 페이지를 다운받는 태스크는 시간차를 두고 실행할 것
    - 위 요구사항을 만족하려면 웹사이트의 호스트명과 작업스레드 사이의 관계를 유지 하면 됨
      - 다운로드 스레드는 별도 큐를 가지고 있어 해당 큐에서 꺼낸 URL 만 다운로드 한다.

    ![4](https://github.com/SoonMyeong/SoonMyeong.github.io/assets/31875043/f46b639e-c37e-422e-b9b0-4225bfc73f7b)

  - 큐 라우터 : 같은 호스트에 속한 URL은 언제나 같은 큐 (b1, b2…) 로 가도록 보장
  - 매핑 테이블 : 호스트 이름과 큐 사이의 관계 매핑
  - 큐 : 같은 호스트에 속한 URL 은 언제나 같은 큐에 보관 됨
  - 큐 선택기 : 큐 선택기는 큐를 순회하며 큐에서 URL 을 꺼내 지정된 스레드에 전달
  - 작업스레드
    - 전달된 URL 을 다운로드하는 작업 수행
    - 전달된 URL 은 순차 처리 & 일정 지연시간 둘 수 있음

- 우선순위
  - 페이지랭크, 트래픽양, 갱신 빈도 등 다양한 척도를 사용할 수 있음

    ![5](https://github.com/SoonMyeong/SoonMyeong.github.io/assets/31875043/667ab323-53a2-4471-9e08-3a85b1bbc764)

    - 큐 선택기 : 우선순위가 높을수록 큐에서 더 자주 꺼내도록 프로그램되어 있음

- 예절과 우선순위를 합친 모습

![6](https://github.com/SoonMyeong/SoonMyeong.github.io/assets/31875043/b67070be-58e4-4636-b377-d0a192162a16)

- 신선도
  - 최신데이터를 유지하기 위해 이미 다운로드한 페이지라해도 주기적으로 재수집할 필요가 있음
  - 우선순위를 활용해 중요한 페이지 위주로 좀 더 재수집

### HTML 다운로더

- 로봇 제외 프로토콜 (Robot Exclusion Protocol)
- Robots.txt
  - 웹사이트가 크롤러와 소통하는 표준방법
  - Robots.txt 파일을 중복 다운로드 하는 것을 피하기 위해 이 파일은 주기적으로 다시 받아 캐시에 보관
- 성능 최적화
  - 분산 크롤링: 크롤링 작업을 여러 서버에 분산
  - 도메인 이름 변환 결과 캐시
    - DNS 요청을 보내고 결과 받는 작업의 동기적 특성 때문에 이를 캐시하여 성능 올리기
      - 주기적으로 도메인이름과 IP 관계 크론 잡 등을 돌려 갱신 설정
  - 지역성
    - 서버 지역별로 분산
  - 짧은 타임아웃
- 안정성
  - 안정 해시
  - 크롤링 상태 및 수집 데이터 저장
  - 예외처리
  - 데이터 검증
- 확장성

  ![7](https://github.com/SoonMyeong/SoonMyeong.github.io/assets/31875043/ed8af051-7a13-4c67-88a1-2ccf9f5de15b)

  ### 문제 있는 컨텐츠 감지 및 회피

  - 중복 컨텐츠 : 웹 컨텐츠의 30% 가량은 중복이다. 해시나 체크섬 사용 하여 중복 탐지
  - 거미 덫
    - 만능 해결책 따윈 없음.
    - 사람이 수작업으로 덫을 확인하고 찾아낸 후 덫이 있는 사이트는 크롤러 탐색 대상에서 제외하거나 URL 필터 목록에 걸어두기
  - 데이터 노이즈
    - 쓸모없는건 제외


  그림출처
  - [https://velog.io/@kyy00n/대규모-시스템-설계-기초-9장.-웹-크롤러-설계](https://velog.io/@kyy00n/%EB%8C%80%EA%B7%9C%EB%AA%A8-%EC%8B%9C%EC%8A%A4%ED%85%9C-%EC%84%A4%EA%B3%84-%EA%B8%B0%EC%B4%88-9%EC%9E%A5.-%EC%9B%B9-%ED%81%AC%EB%A1%A4%EB%9F%AC-%EC%84%A4%EA%B3%84)
  - https://jonghoonpark.com/2023/06/22/web-crawler
